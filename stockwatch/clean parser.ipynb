{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.firefox_profile import FirefoxProfile\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df = pd.read_csv('constituents_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = list(ticker_df['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhav1k\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\zhav1k\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "list_news = []\n",
    "site = 'http://stockwatch.com'\n",
    "for number in range(1, len(ticker_list)):\n",
    "    profile = FirefoxProfile()\n",
    "    profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", 'application/zip, application/x-zip')\n",
    "    profile.set_preference(\"browser.download.folderList\", 2)\n",
    "    profile.set_preference(\"browser.download.dir\", \"C:/Users/zhav1k/Documents/Python Scripts/diploma/custom_data/stockwatch\")\n",
    "    driver = webdriver.Firefox(firefox_profile=profile)\n",
    "    url = 'https://www.stockwatch.com/News/Search.aspx'\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    login = driver.find_element_by_xpath((\"//input[@id='PowerUserName'][@name='ctl00$PowerUserName']\"))\n",
    "    login.send_keys(\"zhav1k\")\n",
    "    pss = driver.find_element_by_xpath((\"//input[@id='PowerPassword'][@name='ctl00$PowerPassword']\"))\n",
    "    pss.send_keys('1008985')\n",
    "    lgn = driver.find_element_by_xpath((\"//input[@id='Login'][@class='sprite login_button']\"))\n",
    "    lgn.click()\n",
    "\n",
    "    login = driver.find_element_by_xpath((\"//input[@id='PowerUserName'][@name='ctl00$PowerUserName']\"))\n",
    "    login.send_keys(\"zhav1k\")\n",
    "    pss = driver.find_element_by_xpath((\"//input[@id='PowerPassword'][@name='ctl00$PowerPassword']\"))\n",
    "    pss.send_keys('1008985')\n",
    "    lgn = driver.find_element_by_xpath((\"//input[@id='Login'][@class='sprite login_button']\"))\n",
    "    lgn.click()\n",
    "    \n",
    "    ticker = driver.find_element_by_xpath((\"//input[@id='MainContent_tSymbol'][@name='ctl00$MainContent$tSymbol']\"))\n",
    "    ticker.send_keys(str(ticker_list[number]))\n",
    "    date = driver.find_element_by_name('ctl00$MainContent$tSymbolFrom')\n",
    "    date.clear()\n",
    "    date.send_keys('20090101')\n",
    "\n",
    "    all_us = Select(driver.find_element_by_xpath(\"//select[@id='MainContent_dSymbolFeed'][@name = 'ctl00$MainContent$dSymbolFeed']\"))\n",
    "\n",
    "    all_us.select_by_value('U')\n",
    "\n",
    "    button = driver.find_element_by_xpath((\"//input[@id='MainContent_bSymbol'][@class='sprite submit_button']\"))\n",
    "    button.click()\n",
    "    \n",
    "    soup_frst =BeautifulSoup(driver.page_source)\n",
    "    a = soup_frst.find('tr', { \"class\" : ['gridViewPager']})\n",
    "    num_pages = int(a.findAll('a')[-1].text)\n",
    "    \n",
    "    \n",
    "    for page in range(1, num_pages + 1):\n",
    "        if page == 1:\n",
    "            soup =BeautifulSoup(driver.page_source)\n",
    "            for link in soup.findAll('tr', { \"class\" : [\"gridViewRow\", 'gridViewAltRow']}):\n",
    "                r = requests.get(site + link.findAll('a')[1]['href'] )\n",
    "                soup_test = BeautifulSoup(r.text)\n",
    "                art = \"\"\n",
    "                try:\n",
    "                    for txt in soup_test.find('span', {'id': 'MainContent_NewsText'}):    \n",
    "                        try:\n",
    "                            art+= txt.text\n",
    "                        except AttributeError:\n",
    "                            continue\n",
    "                except TypeError:\n",
    "                    continue\n",
    "                list_news.append({'Date': link.find('td').text, 'ticker': link.find('a').text, 'title': link.findAll('a')[1].text, 'article': art})\n",
    "        else:\n",
    "            driver.find_element_by_link_text(str(page)).click()\n",
    "            soup =BeautifulSoup(driver.page_source)\n",
    "            for link in soup.findAll('tr', { \"class\" : [\"gridViewRow\", 'gridViewAltRow']}):\n",
    "                r = requests.get(site + link.findAll('a')[1]['href'] )\n",
    "                soup_test = BeautifulSoup(r.text)\n",
    "                art = \"\"\n",
    "                try:\n",
    "                    \n",
    "                    for txt in soup_test.find('span', {'id': 'MainContent_NewsText'}):    \n",
    "                        try:\n",
    "                            art+= txt.text\n",
    "                        except AttributeError:\n",
    "                            continue\n",
    "                except TypeError:\n",
    "                    continue\n",
    "                list_news.append({'Date': link.find('td').text, 'ticker': link.find('a').text, 'title': link.findAll('a')[1].text, 'article': art})\n",
    "    \n",
    "    df = pd.DataFrame(list_news)\n",
    "    df.to_csv('ticker_' + str(number) + '.csv', index = False)\n",
    "    list_news = []\n",
    "    del(df)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
